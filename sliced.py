# -*- coding: utf-8 -*-
"""Sliced

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LBCCZZSsF8hg73RT96QUEuDWwDl4PfMi

Idea is to predict song popularity based on given parameters. 
Problem can be found on link below
https://www.kaggle.com/c/sliced-s01e08-KJSEks/overview
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.preprocessing   import MinMaxScaler as mnx 

import warnings
warnings.filterwarnings('ignore')

train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/SLICED Prediction - Kaggle/train.csv')
test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/SLICED Prediction - Kaggle/test.csv')
artist = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/SLICED Prediction - Kaggle/artists.csv')

test_orig = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/SLICED Prediction - Kaggle/test.csv')

train.info()

train.describe()

print('Max Duration of Song (in micro second): ',train.duration_ms.max())
print('Least Duration of Song (in micro second): ',train.duration_ms.min())
print('Mediam Duration of Song (in micro second): ',train.duration_ms.median())
print('Mean Duration of Song (in micro second): ',train.duration_ms.mean())

train['duration_mins'] = train.duration_ms / 60000
test['duration_mins']  = test.duration_ms / 60000

def plotfun(x,y,title):
  fig,ax = plt.subplots(1,4,squeeze=False,figsize=(20,10))
  #fig = plt.figure(figsize=(20,20))

  plt.subplot(141)
  sns.scatterplot(x,y)
  plt.suptitle(title,fontsize=30)

  ax1 = plt.subplot(142)
  sns.boxplot(y=x)
  ax1.title.set_text('Box Plot')
  ax2 = plt.subplot(143)
  ax2.get_yaxis().set_visible(True)
  ax2.title.set_text('Violin Plot')
  sns.violinplot(y=x)


  ax3 = plt.subplot(144)
  ax3 = sns.histplot(x)
  ax3.title.set_text('Distribution')

  plt.show()

plotfun(train.duration_mins,train.popularity,'Song duration (in Minutes) vs Popularity')
plotfun(train.danceability * 100,train.popularity,'Danceability vs Popularity')
plotfun(train.energy,train.popularity,'Energy vs Popularity')
plotfun(train.loudness,train.popularity,'Loundness vs Popularity')
plotfun(train.speechiness,train.popularity,'Speechiness vs Popularity')
plotfun(train.instrumentalness,train.popularity,'instrumentalness vs Popularity')
plotfun(train.liveness,train.popularity,'Liveness vs Popularity')
plotfun(train.valence,train.popularity,'Valence vs Popularity')
plotfun(train.tempo,train.popularity,'tempo vs Popularity')

"""- Many outliers for song duration
- Most of the songs are under 20 minutes duration


- Popularity is well distributed with dancebility. 
- there are few outliers
- Column is well distributed


- Popularity is well distributed with Energy
- No outliers visibile
- Column is well distributed


- most of songs are on higher loudness side
- Higher loudness has more popularity
- there are outliers


- Speechiness is well distributed across popularity
- There are many outliers and hence, data is skewed


- Instrumentalness and liveness is well distributed across popularity
- There are many outliers and hence, data is skewed


- Valence and Tempo does not have outliers
- Are well distributed

"""

q1 = train.quantile(.25)
q3 = train.quantile(.75)
iqr = q3-q1

outlirs = ((train < (q1 - 1.5* iqr)) | (train > (q3 + 1.5* iqr)))
print('Number of outliers are ',(outlirs.apply(lambda a: sum(a),axis=1) > 0).sum())

print('Number of outliers in each column')
outlirs.sum()

plt.figure(figsize=(10,5))
plt.title('Popularity vs Key')
sns.barplot(train.key,train.popularity)

"""There isn't much variation between Keys and Popularity"""

plt.figure(figsize=(20,8))
sns.barplot(train.release_year,train.popularity,ci=None)
plt.xticks(rotation=70)
plt.tight_layout()

"""Overall, popularity appears to be increasing with year"""

train.isnull().sum()

"""Release Month and Year has most missing values. We will not use these column. Name has one missing value, we not going to use that either"""

plt.figure(figsize=(10,10))
df_sub = train.iloc[:,[2,6,7,9,10,11,12,13,14,15,16,19]]
corr_mat = df_sub.corr()
sns.heatmap(corr_mat,annot=True)
plt.show()

"""Since Year has high correlation with Popularity, we need to utilize that column.
We can break the years in 1980's,1990' and so on
"""

train['release_years'] = train.release_year//10
test['release_years'] = test.release_year//10

cols = ['danceability', 'energy','duration_ms','loudness', 'speechiness','acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','release_years','popularity']
x = train.loc[:,cols]
y = train.popularity

test.info()

y = x.popularity
x = x.drop(['popularity'],axis=1)

x.release_years = x.release_years.astype('object')

test.release_years = test.release_years.astype('object')
test = pd.get_dummies(test,drop_first=True)

x = pd.get_dummies(x,drop_first=True)

x.info()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.3,random_state=42)

x_train.describe()

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

def selc_features(x_train,y_train,x_test,n):
  fs = SelectKBest(score_func=f_regression,k=n)
  fs.fit(x_train,y_train)
  x_train_fs = fs.transform(x_train)
  #x_test_fs = fs.transform(x_test)
  return x_train_fs,fs

x_sel,fs = selc_features(x,y,x_test,15)

for i in range(len(fs.scores_)):
  print('Feature %d: %f'%(i,fs.scores_[i]))

plt.bar([i for i in range(len(fs.scores_))],fs.scores_)
plt.show()

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold

cv = StratifiedKFold(n_splits=10,random_state=42)
model = LinearRegression()
#model.fit(x_train,y_train)
a = cross_val_score(model,x_sel,y,cv=cv)
a.mean()
#ypred = model.predict(x_test)

from sklearn.preprocessing import RobustScaler
trans = RobustScaler().fit(x)
x = trans.transform(x)

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold

cv = StratifiedKFold(n_splits=3,random_state=42)
model = LinearRegression()
#model.fit(x_train,y_train)
a = cross_val_score(model,x_sel,y,cv=cv)
a.mean()
#ypred = model.predict(x_test)

x.info()

from sklearn.ensemble import RandomForestRegressor
cv = StratifiedKFold(n_splits=3,random_state=42)
model = RandomForestRegressor(max_features=None)
a = cross_val_score(model,x,y,cv=cv)
a.mean()

x.info()

model = RandomForestRegressor()
model.fit(x,y)
pred = model.predict(test)

pred.shape

final = pd.DataFrame(pred,index=test_orig.id,columns=['popularity'])

final.to_csv('submission.csv',index=True)